{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6706c596",
   "metadata": {},
   "source": [
    "### 1. What is your definition of clustering? What are a few clustering algorithms you might think of?\n",
    "Clustering is a unsupervised learning technique that involves grouping data points that are similar to each other. Some clustering algorithms include K-Means, Hierarchical Clustering, and DBSCAN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b89a3",
   "metadata": {},
   "source": [
    "### 2. What are some of the most popular clustering algorithm applications?\n",
    "Popular clustering algorithm applications include image segmentation, customer segmentation, and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9a453",
   "metadata": {},
   "source": [
    "### 3. When using K-Means, describe two strategies for selecting the appropriate number of clusters.\n",
    "Two strategies for selecting the appropriate number of clusters in K-Means include the elbow method and silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cdb4f",
   "metadata": {},
   "source": [
    "### 4. What is mark propagation and how does it work? Why would you do it, and how would you do it?\n",
    "Mark propagation is a semi-supervised learning technique that involves labeling a few instances and propagating these labels to the rest of the dataset based on similarity measures. This can be useful for tasks such as image segmentation or text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c702534",
   "metadata": {},
   "source": [
    "### 5. Provide two examples of clustering algorithms that can handle large datasets. And two that look for high-density areas?\n",
    "Examples of clustering algorithms that can handle large datasets include Mini-Batch K-Means and DBSCAN. Examples of clustering algorithms that look for high-density areas include Mean-Shift and Density-Based Spatial Clustering of Applications with Noise (DBSCAN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa60e7c",
   "metadata": {},
   "source": [
    "### 6. Can you think of a scenario in which constructive learning will be advantageous? How can you go about putting it into action?\n",
    "Constructive learning is advantageous in scenarios where there is a limited labeled dataset, but unlabeled data is abundant. It involves first learning a simpler model on the labeled data, and then using this model to generate new labels for the unlabeled data, which can then be used to train a more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b759e2d",
   "metadata": {},
   "source": [
    "### 7. How do you tell the difference between anomaly and novelty detection?\n",
    "Anomaly detection involves identifying instances that are significantly different from the majority of instances, while novelty detection involves identifying instances that are significantly different from instances in the training set. In other words, anomaly detection looks for outliers, while novelty detection looks for new or unseen instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46da218",
   "metadata": {},
   "source": [
    "### 8. What is a Gaussian mixture, and how does it work? What are some of the things you can do about it?\n",
    "A Gaussian mixture is a model that assumes the data was generated from a mixture of Gaussian distributions. It works by estimating the means and covariances of the Gaussian distributions, and then using the probability densities of these distributions to determine which cluster each instance belongs to. Some things you can do with Gaussian mixture models include finding the optimal number of clusters and generating new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9a105",
   "metadata": {},
   "source": [
    "### 9. When using a Gaussian mixture model, can you name two techniques for determining the correct number of clusters?\n",
    "Two techniques for determining the correct number of clusters when using a Gaussian mixture model include the Akaike information criterion (AIC) and the Bayesian information criterion (BIC)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
