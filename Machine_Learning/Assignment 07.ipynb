{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1959a3",
   "metadata": {},
   "source": [
    "### 1. What is the definition of a target function ? In the sense of a real-life example, express the target function. How is a target function's fitness assessed ?\n",
    "A target function is a mathematical representation that maps input variables to an output variable. It is used in supervised learning to predict the outcome of new data. For example, in predicting house prices, the target function would map input variables such as size, location, and number of bedrooms to the output variable, the price. The fitness of the target function is assessed by measuring its ability to accurately predict outcomes on a set of validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b3461",
   "metadata": {},
   "source": [
    "### 2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.\n",
    "Predictive models aim to forecast or estimate an outcome based on given inputs. Examples include linear regression, decision trees, and neural networks. Descriptive models, on the other hand, aim to summarize and understand patterns in data, such as clustering algorithms and association rule mining. The distinction between the two lies in their objectives, with predictive models aiming to make predictions, while descriptive models aim to summarize and understand data patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afebdbcb",
   "metadata": {},
   "source": [
    "### 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters.\n",
    "\n",
    "The efficiency of a classification model can be assessed using various evaluation metrics, such as accuracy, precision, recall, F1 score, and ROC curve.\n",
    "\n",
    "Accuracy: It measures the proportion of correct predictions out of all the predictions made. It is calculated as (TP+TN)/(TP+TN+FP+FN), where TP is true positive, TN is true negative, FP is false positive, and FN is false negative.\n",
    "Precision: It measures the proportion of true positives out of all the positive predictions made. It is calculated as TP/(TP+FP).\n",
    "Recall: It measures the proportion of true positives out of all the actual positives. It is calculated as TP/(TP+FN).\n",
    "F1 score: It is the harmonic mean of precision and recall, and provides a balanced evaluation metric for models with uneven class distribution. It is calculated as 2*(precision*recall)/(precision+recall).\n",
    "ROC curve: It is a graphical representation of the trade-off between true positive rate (TPR) and false positive rate (FPR) at various classification thresholds. A good classifier is expected to have a curve close to the top-left corner of the plot, indicating high TPR and low FPR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74638ca2",
   "metadata": {},
   "source": [
    "### Describe :\n",
    "1. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    "2. What does it mean to overfit? When is it going to happen?\n",
    "3. In the sense of model fitting, explain the bias-variance trade-off.\n",
    "\n",
    "Underfitting occurs when a model is too simple to capture the complexity of the data, resulting in poor performance. The most common reason for underfitting is using too few features or too simple a model.\n",
    "\n",
    "Overfitting occurs when a model is too complex and adapts too much to the training data, causing it to perform poorly on new data. It usually happens when a model is over-parameterized or the data is noisy.\n",
    "\n",
    "The bias-variance trade-off refers to the balance between a model's ability to fit the data well (low bias) and its ability to generalize to new data (low variance). A model with high bias will underfit the data, while a model with high variance will overfit the data. Finding the right balance between bias and variance is essential to building a good predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c854e1",
   "metadata": {},
   "source": [
    "### 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n",
    "\n",
    "Yes, it is possible to improve the performance of a learning model. The following approaches can be used:\n",
    "\n",
    "1. Increase the amount of data used for training.\n",
    "2. Use more sophisticated algorithms or ensemble methods.\n",
    "3. Perform hyperparameter tuning.\n",
    "4. Feature engineering can also improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9c1f78",
   "metadata": {},
   "source": [
    "### 6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?\n",
    "The success of an unsupervised learning model can be evaluated by different metrics, depending on the type of problem and the algorithm used. Common success indicators include clustering accuracy, silhouette score, and reconstruction error. However, since unsupervised learning models do not have a clear target variable, the evaluation of their success is often subjective and requires domain expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700b532",
   "metadata": {},
   "source": [
    "### 7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.\n",
    "No, it is not recommended to use a classification model for numerical data or a regression model for categorical data. This is because these models are designed to work with specific types of data and have different assumptions about the relationship between the input and output variables. Using a model inappropriately can lead to inaccurate predictions or unreliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8444eea",
   "metadata": {},
   "source": [
    "### 8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?\n",
    "The predictive modeling method for numerical values involves building a regression model to predict a continuous numerical target variable. This is different from categorical predictive modeling, where the goal is to predict a categorical target variable using a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d19c9",
   "metadata": {},
   "source": [
    "### 10. Make quick notes on:\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters\n",
    "\n",
    "`The process of holding out:` Refers to the practice of setting aside a portion of the available data for testing the performance of a machine learning model trained on the remaining data.\n",
    "`Cross-validation by tenfold:` A technique used to evaluate the performance of a machine learning model by dividing the data into ten equal parts, training the model on nine parts and validating it on the remaining part in a loop.\n",
    "`Adjusting the parameters:` The process of tuning the hyperparameters of a machine learning model in order to improve its performance on the validation data. It involves selecting the optimal set of hyperparameters that results in the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f24b1",
   "metadata": {},
   "source": [
    "### 11. Define the following terms:\n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner\n",
    "\n",
    "`Purity` refers to the degree to which each cluster consists of only one class, whereas `silhouette` width is a measure of how similar an object is to its own cluster compared to other clusters.\n",
    "\n",
    "`Boosting and Bagging` are two types of ensemble learning methods. Boosting combines multiple weak models to create a strong model, while Bagging uses bootstrap sampling to generate multiple independent models.\n",
    "\n",
    "`The eager learner` is a machine learning algorithm that tries to build a generalized model from the entire training data set during the training phase, whereas the `lazy learner` postpones generalization until prediction time and keeps the training data until that time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
