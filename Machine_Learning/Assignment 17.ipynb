{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32726ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Using a graph to illustrate slope and intercept, define basic linear regression.\n",
    "2. In a graph, explain the terms rise, run, and slope.\n",
    "3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the different conditions that contribute to the slope.\n",
    "4. Use a graph to demonstrate curve linear negative slope and curve linear positive slope.\n",
    "5. Use a graph to show the maximum and low points of curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493cc147",
   "metadata": {},
   "source": [
    "### 1. Using a graph to illustrate slope and intercept, define basic linear regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef67f5",
   "metadata": {},
   "source": [
    "### 2. In a graph, explain the terms rise, run, and slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e07d6",
   "metadata": {},
   "source": [
    "### 3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the different conditions that contribute to the slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792f976",
   "metadata": {},
   "source": [
    "### 4. Use a graph to demonstrate curve linear negative slope and curve linear positive slope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23dc27",
   "metadata": {},
   "source": [
    "### 5. Use a graph to show the maximum and low points of curves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f3766",
   "metadata": {},
   "source": [
    "### 6. Use the formulas for a and b to explain ordinary least squares.\n",
    "Ordinary Least Squares (OLS) is a method for estimating the unknown parameters of a linear regression model by minimizing the sum of the squared residuals. The formulas for a and b represent the intercept and slope of the regression line, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d1e97",
   "metadata": {},
   "source": [
    "### 7. Provide a step-by-step explanation of the OLS algorithm.\n",
    "The OLS algorithm involves calculating the slope and intercept of the regression line using the formulas for a and b, then finding the residuals, summing their squares, and minimizing the sum to obtain the best-fit line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8694e38",
   "metadata": {},
   "source": [
    "### 8. What is the regression's standard error? To represent the same, make a graph.\n",
    "The regression's standard error is a measure of the variability in the residuals around the regression line. A graph of the residuals versus the predicted values can be used to represent the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31ef35",
   "metadata": {},
   "source": [
    "### 9. Provide an example of multiple linear regression.\n",
    "Multiple linear regression is a statistical technique used to model the relationship between two or more independent variables and a dependent variable. For example, a study may use multiple linear regression to examine the relationship between a person's age, income, and education level, and their likelihood of voting in a political election."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb0cc62",
   "metadata": {},
   "source": [
    "### 10. Describe the regression analysis assumptions and the BLUE principle.\n",
    "Regression analysis assumptions include linearity, homoscedasticity, independence of errors, normality of errors, and absence of multicollinearity. The BLUE (Best Linear Unbiased Estimators) principle states that the OLS estimates are the best linear unbiased estimates of the regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf440275",
   "metadata": {},
   "source": [
    "### 11. Describe two major issues with regression analysis.\n",
    "Two major issues with regression analysis include multicollinearity, which occurs when independent variables are highly correlated with each other, and heteroscedasticity, which occurs when the variance of the errors is not constant across all values of the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb04eb5",
   "metadata": {},
   "source": [
    "### 12. How can the linear regression model's accuracy be improved?\n",
    "The accuracy of the linear regression model can be improved by including more relevant independent variables, transforming the data to fit a linear model better, or using a different type of regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54542f39",
   "metadata": {},
   "source": [
    "### 13. Using an example, describe the polynomial regression model in detail.\n",
    "Polynomial regression is a technique used to model the relationship between an independent variable and a dependent variable with a polynomial function. For example, a study may use polynomial regression to examine the relationship between a person's age and their risk of heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397aa754",
   "metadata": {},
   "source": [
    "### 14. Provide a detailed explanation of logistic regression.\n",
    "Logistic regression is a statistical technique used to model the probability of a binary outcome, such as whether a person will develop a disease or not. It estimates the probability of the outcome as a function of the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a3b9fa",
   "metadata": {},
   "source": [
    "### 15. What are the logistic regression assumptions?\n",
    "Logistic regression assumptions include linearity, independence of errors, absence of multicollinearity, and a binary outcome variable. The logistic regression model assumes that the log-odds of the outcome are linearly related to the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b810b",
   "metadata": {},
   "source": [
    "### 16. Go through the details of maximum likelihood estimation.\n",
    "Maximum likelihood estimation is a method used to estimate the parameters of a statistical model by finding the values that maximize the likelihood function, which is a measure of how well the model fits the data. It is commonly used in logistic regression to estimate the coefficients of the independent variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
