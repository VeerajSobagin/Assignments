{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2236131",
   "metadata": {},
   "source": [
    "### 1. Explain convolutional neural network, and how does it work?\n",
    "Convolutional Neural Network (CNN) is a deep learning architecture that is commonly used in image recognition and computer vision tasks. CNNs consist of convolutional layers, pooling layers, and fully connected layers. The convolutional layer performs feature extraction by convolving the input image with a set of filters to produce a feature map. Pooling layers reduce the size of the feature maps by down-sampling, and fully connected layers perform classification based on the extracted features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc9377",
   "metadata": {},
   "source": [
    "### 2. How does refactoring parts of your neural network definition favor you?\n",
    "Refactoring parts of a neural network definition can make the network more modular and easier to modify, improve the overall efficiency of the network, and help to avoid overfitting. Refactoring can involve changing the architecture of the network, reusing parts of the network, or introducing regularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf2532",
   "metadata": {},
   "source": [
    "### 3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason for this?\n",
    "Flattening refers to the process of converting a multidimensional array or tensor into a one-dimensional array or vector. In the MNIST CNN, flattening is necessary because the output of the convolutional layers is a 3-dimensional tensor, and the fully connected layers require a 1-dimensional input. Flattening allows the output of the convolutional layers to be fed into the fully connected layers for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56845593",
   "metadata": {},
   "source": [
    "### 4. What exactly does NCHW stand for?\n",
    "NCHW stands for \"Number of samples\", \"Number of channels\", \"Height\", and \"Width\", respectively. This is a data format commonly used in deep learning frameworks such as PyTorch and Caffe, where the input data is represented as a 4-dimensional tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dedaf80",
   "metadata": {},
   "source": [
    "### 5. Why are there 7*7*(1168-16) multiplications in the MNIST CNN's third layer?\n",
    "The third layer of the MNIST CNN has 1168 filters, each of size 7x7. The input to this layer is a 13x13x32 tensor, and the output is a 7x7x1168 tensor. Therefore, there are 7x7x1168x(13x13x32) = 7x7x(1168-16) multiplications in this layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b25aa7",
   "metadata": {},
   "source": [
    "### 6.Explain definition of receptive field?\n",
    "Receptive field refers to the region of the input image that a neuron in the convolutional layer is sensitive to. The receptive field of a neuron in a given layer is determined by the size of the filter and the stride of the convolutional operation in previous layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2ef63",
   "metadata": {},
   "source": [
    "### 7. What is the scale of an activation's receptive field after two stride-2 convolutions? What is the reason for this?\n",
    "After two stride-2 convolutions, the scale of an activation's receptive field is 4 times the scale of the receptive field before the convolutions. This is because each stride-2 convolution reduces the size of the feature map by a factor of 2, and the receptive field size is proportional to the size of the feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4360bdb",
   "metadata": {},
   "source": [
    "### 8. What is the tensor representation of a color image?\n",
    "A color image can be represented as a 3-dimensional tensor with dimensions (height, width, channels), where the channels represent the intensity of the red, green, and blue color channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f505c09",
   "metadata": {},
   "source": [
    "### 9. How does a color input interact with a convolution?\n",
    "In a convolutional layer, a color input interacts with the filters in the same way as a grayscale input. The filters are applied independently to each color channel, and the resulting feature maps are combined to produce the output tensor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
