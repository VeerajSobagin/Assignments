{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13407d21",
   "metadata": {},
   "source": [
    "### 1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
    "CNNs are better suited for image classification tasks due to their ability to learn spatial features from local regions of the image, allowing for translation invariance and reduced sensitivity to image distortions. They also have significantly fewer parameters, allowing for faster training and less overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900eafb",
   "metadata": {},
   "source": [
    "### 2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of 2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels. What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much RAM will this network require when making a prediction for a single instance? What about when training on a mini-batch of 50 images?\n",
    "The total number of parameters in the CNN is approximately 1.2 million. When making a prediction for a single instance, the network will require at least 18MB of RAM. When training on a mini-batch of 50 images, the network will require at least 900MB of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa56c39",
   "metadata": {},
   "source": [
    "### 3. If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?\n",
    "Some potential solutions to a GPU running out of memory while training a CNN include reducing batch size, reducing image size or resolution, using a smaller network, using mixed precision training, and using gradient checkpointing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05948e",
   "metadata": {},
   "source": [
    "### 4. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?\n",
    "A max pooling layer can help to reduce the dimensionality of the input data while still retaining important features. This can help to prevent overfitting and improve the generalization of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695115ff",
   "metadata": {},
   "source": [
    "### 5. When would you want to add a local response normalization layer?\n",
    "A local response normalization layer can be added to a CNN to help improve the model's ability to generalize by normalizing the activity of neighboring neurons in the same feature map. This can help to improve the model's performance by reducing the impact of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc42bb6",
   "metadata": {},
   "source": [
    "### 6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
    "AlexNet introduced several innovations compared to LeNet-5, including the use of rectified linear units (ReLU) activation functions, dropout regularization, and data augmentation. GoogLeNet introduced the concept of an inception module, ResNet introduced skip connections to combat the vanishing gradient problem, SENet introduced squeeze-and-excitation blocks to improve feature attention, and Xception introduced depthwise separable convolutions to reduce the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e21882",
   "metadata": {},
   "source": [
    "### 7. What is a fully convolutional network? How can you convert a dense layer into a convolutional layer?\n",
    "A fully convolutional network is a type of neural network that consists only of convolutional layers and does not include any fully connected layers. To convert a dense layer into a convolutional layer, the weights of the dense layer are reshaped into a convolutional filter and applied to the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25a61b",
   "metadata": {},
   "source": [
    "### 8. What is the main technical difficulty of semantic segmentation?\n",
    "The main technical difficulty of semantic segmentation is the trade-off between accuracy and computational efficiency. High accuracy requires the use of complex models, but these models can be computationally expensive and difficult to train. Finding a balance between accuracy and efficiency is a major challenge in semantic segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78100a91",
   "metadata": {},
   "source": [
    "### 9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f13443",
   "metadata": {},
   "source": [
    "### 10. Use transfer learning for large image classification, going through these steps:\n",
    "    a. Create a training set containing at least 100 images per class. For example, you could classify your own pictures based on the location (beach, mountain, city, etc.), or alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "    b. Split it into a training set, a validation set, and a test set.\n",
    "    c. Build the input pipeline, including the appropriate preprocessing operations, and optionally add data augmentation.\n",
    "    d. Fine-tune a pretrained model on this dataset.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
